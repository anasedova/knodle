{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to find names of people killed by the police in a corpus of news paper articles. The corpus was created by Katherine A. Keith et al. (2017) for a similar task using distant supervision. This dataset contains mentions of people (based on keywords related to “killing” or “police”) who might have been killed by the police. The dataset (the HTML documents scraped in 2016 themselves as well as the already sentence-segmented data) are available on the [project’s website](http://slanglab.cs.umass.edu/PoliceKillingsExtraction/) and on [MinIO]( https://knodle.dm.univie.ac.at/minio/knodle/datasets/police_killing/). \n",
    "There is a train and a test dataset, both of them containing dictionaries with the following keys:\n",
    "\n",
    "-\tdocid: unique identifiers of every mention of a person possible killed by the police\n",
    "-\tname: the normalized name of the person\n",
    "-\tdownloadtime: time the document was downloaded\n",
    "-\tnames_org: the original name of the person mentioned in the document\n",
    "-\tsentnames: other names in the mention (not of the person possibly killed by the police)\n",
    "-\tsent_alter: the mention, name of the person possible killed by the policed replaced by “TARGET”, any other names replaced by “POLICE”\n",
    "-\tplabel: for the training data possibly erroneous labels obtained using weak supervision and gold labels for the test data – in this project, only the labels of the test data will be used\n",
    "-\tsent_org: the original mention\n",
    "\n",
    "\n",
    "The rules that are used in this notebook are simple wordpairs (one of the killing and one of the police related keywords each). A rule matches a sample if both of the words in the wordpair are part of the sample.\n",
    "\n",
    "Reference: Keith, Kathrine A. et al. (2017): Identifying civilians killed by police with distantly supervised entity-event extraction. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. doi: [10.18653/v1/D17-1163](https://aclanthology.org/D17-1163/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from joblib import dump\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "First of all, the file names for the output at the end of this notebook are defined. After that, the raw data can be downloaded from MinIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Emilie/Uni/2021WS/DS_project/data/police_killing'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the files names\n",
    "Z_MATRIX_TRAIN = \"train_rule_matches_z.lib\"\n",
    "Z_MATRIX_DEV = \"dev_rule_matches_z.lib\"\n",
    "Z_MATRIX_TEST = \"test_rule_matches_z.lib\"\n",
    "\n",
    "T_MATRIX_TRAIN = \"mapping_rules_labels_t.lib\"\n",
    "\n",
    "TRAIN_SAMPLES_OUTPUT = \"df_train.lib\"\n",
    "DEV_SAMPLES_OUTPUT = \"df_dev.lib\"\n",
    "TEST_SAMPLES_OUTPUT = \"df_test.lib\"\n",
    "\n",
    "# file names for .csv files\n",
    "TRAIN_SAMPLES_CSV = \"df_train.csv\"\n",
    "DEV_SAMPLES_CSV = \"df_dev.csv\"\n",
    "TEST_SAMPLES_CSV = \"df_test.csv\"\n",
    "\n",
    "# define the path to the folder where the data will be stored\n",
    "#data_path = \"../../../data/police_killing\"\n",
    "data_path = \"C:/Users/Emilie/Uni/2021WS/DS_project/data/police_killing\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.path.join(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the keywords**\n",
    "\n",
    "Downloading the keywords from MiniO that will later be used to create the rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = pd.read_csv(os.path.join(data_path, \"keywords.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the Train data**\n",
    "\n",
    "We read the downloaded data and convert it to a Pandas Dataframe. For now, we take only the samples for the train data and the samples as well as the labels for the test data. In the end, we will also need the name of the person in case it turns out they were killed by the police. However, in this step their name should be replaced by the TARGET symbol. Therefore, we only take the values for the \"sent_alter\" key and rename them to \"samples\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# later first downloaded from Minio\n",
    "\n",
    "def get_train_data(data_path):\n",
    "    with open(os.path.join(data_path, \"train.json\"), 'r') as data:\n",
    "        train_data = [json.loads(line) for line in data] #a list of dicts\n",
    "    df_train_sent_alter = pd.DataFrame(train_data, columns = [\"sent_alter\"]).rename(columns={\"sent_alter\": \"samples\"})\n",
    "    return df_train_sent_alter\n",
    "\n",
    "df_train = get_train_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two years earlier , Officer TARGET was killed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Police Chief PERSON said Randolph was found sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the latest incident , Chief Superintendent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chief TARGET of Penn Township police entered t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man was was fatally shot by a police officer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             samples\n",
       "0  Two years earlier , Officer TARGET was killed ...\n",
       "1  Police Chief PERSON said Randolph was found sh...\n",
       "2  In the latest incident , Chief Superintendent ...\n",
       "3  Chief TARGET of Penn Township police entered t...\n",
       "4  A man was was fatally shot by a police officer..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the Development and Test Data**\n",
    "\n",
    "Since the [SLANG Lab](http://slanglab.cs.umass.edu/PoliceKillingsExtraction/) only provides train and test data, but no development data, the test data must be split in order to be able to use some of it for develoment and some of it for testing. The samples for the develoment data will be selected randomly to avoid imbalances of positive and negative sample in dev and test data.\n",
    "\n",
    "The parameter *used_as_dev* is the amount of the gold labeled data that should be used for develoment instead of testing. It is set to 30% for now, but can be changed depending on the application of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30% of the test data will be used for develoment.\n"
     ]
    }
   ],
   "source": [
    "used_as_dev = 30\n",
    "print(f\"{used_as_dev}% of the test data will be used for develoment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dev_test_data(data_path):\n",
    "    with open(os.path.join(data_path, \"test.json\"), 'r') as data:\n",
    "        dev_test_data = [json.loads(line) for line in data]\n",
    "    dev_test_sent_alter = pd.DataFrame(dev_test_data, columns = [\"sent_alter\", \"plabel\"]).rename(columns={\"sent_alter\": \"samples\", \"plabel\": \"label\"})\n",
    "    df_dev = dev_test_sent_alter.sample(n = int(round((dev_test_sent_alter.shape[0]/100)*used_as_dev))).reset_index(drop = True)\n",
    "    df_test = dev_test_sent_alter.drop(df_dev.index).reset_index(drop = True)\n",
    "    return df_dev, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:\n",
      "\n",
      "Train data: 132833\n",
      "Development data: 20678\n",
      "Test data: 48247\n"
     ]
    }
   ],
   "source": [
    "df_dev, df_test = get_dev_test_data(data_path)\n",
    "\n",
    "print(f\"Number of samples:\\n\\nTrain data: {df_train.shape[0]}\\nDevelopment data: {df_dev.shape[0]}\\nTest data: {df_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jakarta police spokesman TARGET said three off...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mecklenburg police release footage of TARGET s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commissioner TARGET split with his colleagues ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Woman killed , TARGET officer wounded in gas s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JULY 30 , 2006 : A Mesa Police Department Crim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             samples  label\n",
       "0  Jakarta police spokesman TARGET said three off...      0\n",
       "1  Mecklenburg police release footage of TARGET s...      1\n",
       "2  Commissioner TARGET split with his colleagues ...      0\n",
       "3  Woman killed , TARGET officer wounded in gas s...      0\n",
       "4  JULY 30 , 2006 : A Mesa Police Department Crim...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ ] TARGET / Chicago Tribune Lake County Major...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Round Lake police shooting Round Lake police s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PERSON shooting PERSON shooting TARGET / Chica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scene of Round Lake police shooting Scene of R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>involved shooting TARGET / Chicago Tribune The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             samples  label\n",
       "0  [ ] TARGET / Chicago Tribune Lake County Major...      0\n",
       "1  Round Lake police shooting Round Lake police s...      0\n",
       "2  PERSON shooting PERSON shooting TARGET / Chica...      0\n",
       "3  Scene of Round Lake police shooting Scene of R...      0\n",
       "4  involved shooting TARGET / Chicago Tribune The...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The classes**\n",
    "\n",
    "Since the goal is to find out whether a sentence describes the killing of a person by the police or does not, it is a binary classification task and there are only two classes. The number of classes is defined as the num_classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper of Keith et al. (2017), two lists of police- and killing-related words are used to extract the relevant mentions: \n",
    "\n",
    "\"*These lists were semi-automatically constructed by looking up the nearest neighbors of “police” and “kill” (by cosine distance) from Google’s public release of word2vec vectors pretrained on a very large (proprietary) Google News corpus,20 and then manually excluding a small number of misspelled words or redundant capitalizations (e.g. “Police” and “police”).*\" (Keith et al. p. 11)\n",
    "\n",
    "The keywords are saved in the CSV that we have already downloaded and read in as a Pandas Dataframe. Now we will use it to create the rules. Each rule is a pair of a police and a killing word, both of these words must appear in sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step, all possible wordpairs are created and added to a dictionary as keys. The values are their unique rule IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rule2id(keywords: pd.DataFrame) -> dict:\n",
    "    \n",
    "    rule2rule_id = dict({})\n",
    "    rule_id = 0\n",
    "    for police_word in keywords[\"police_words\"]:\n",
    "        for kill_word in keywords[\"kill_words\"].dropna():\n",
    "            rule2rule_id[f'{police_word} {kill_word}'] = rule_id\n",
    "            rule_id += 1\n",
    "    \n",
    "    return rule2rule_id\n",
    "\n",
    "rule2rule_id = get_rule2id(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we create a dictionary assigning all rules to their label. There are only two classes (someone was killed by the police or was not killed by the police). Since there are no rules indicating that someone was **not** killed by the police, all rules indicate the positive class 1. Therefore, all values of the rule2label dictionary, containing the rule IDs as keys, can be set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule2label = {rule_id: 1 for rule_id in rule2rule_id.values()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirdly, a dictionary mapping the labels to their ID as well as a dictionary mapping the ID to the corresponding label are required. As there are only two classes, this can be done manually. \n",
    "\n",
    "*@Anastasiia I will need the \"reversed\" label_id2label dict later for my code, but I'm not sure if I'm allowed to to it like this?\n",
    "And is it okay to create it manually?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2label_id ={\"negative\":0, \"positive\":1}\n",
    "label_id2label = {0: \"negative\", 1: \"positive\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building the T matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows of the T matrix are the rules and the columns the classes. The T matrix is one-hot encoded. (1 for a rule and its corresponding class.) It can be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mapping to t matrix \n",
    "(from TAC tutorial)\n",
    "\"\"\"\n",
    "\n",
    "def get_mapping_rules_labels_t(rule2label, num_classes):\n",
    "    \"\"\" Function calculates t matrix (rules x labels) using the known correspondence of relations to decision rules \"\"\"\n",
    "    mapping_rules_labels_t = np.zeros([len(rule2label), num_classes])\n",
    "    for rule, labels in rule2label.items():\n",
    "        mapping_rules_labels_t[rule, labels] = 1\n",
    "    return mapping_rules_labels_t\n",
    "\n",
    "mapping_rules_labels_t = get_mapping_rules_labels_t(rule2label, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## buidling the Z matrix (instances x rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Train Data\n",
    "\n",
    "For now, the wordpairs contained in the rule2rule_id dictionary are simple strings. To use them as actual rules, they need to be converted to RegEx firstly. We create a dictionary containing the strings of wordpairs as keys and a list of the corresponding RegEx as values. It is important to convert them to RegEx in order to be able to look for the exact words in the wordpair. (The words in the rules must not end in another word character (a-z). If the killing word in a rule is, for instance, \"kill\", only sentences containing the word \"kill\" should be matched and no sentences containing words like \"kills\" or \"killed\" because there are separate rules for these words.)\n",
    "\n",
    "Secondly, we apply the RegEx to the samples. In the beginning, everything is stored in a list of dictionaries (one for each individual sample in the train data). The dictionaries contain the sample, a list of that rules that match and a list of the corresponding rule IDs. After that, we convert the list of dictionaries to a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rules2regex(rule2rule_id: dict) -> dict:\n",
    "    \n",
    "    searches = dict({})\n",
    "    \n",
    "    for rule in rule2rule_id.keys():\n",
    "            wordpair = rule.split()\n",
    "            search4police_word = f'{wordpair[0]}\\W'\n",
    "            search4kill_word = f'{wordpair[1]}\\W'\n",
    "            searches[rule] = [search4police_word, search4kill_word]\n",
    "            \n",
    "    return searches\n",
    "\n",
    "\n",
    "def get_data_for_df(data: pd.DataFrame, searches: dict) -> list:\n",
    "\n",
    "    data_for_df = []\n",
    "\n",
    "    for sample in tqdm(data[\"samples\"].drop_duplicates()):\n",
    "        data_dict = dict({})\n",
    "        data_dict[\"samples\"] = sample\n",
    "        data_dict[\"rules\"] = []\n",
    "        data_dict[\"enc_rules\"] = []\n",
    "   \n",
    "        for rule, search in searches.items():\n",
    "            if re.search(search[0], sample.lower()) and re.search(search[1], sample.lower()):\n",
    "                data_dict[\"rules\"].append(rule)\n",
    "                data_dict[\"enc_rules\"].append(rule2rule_id[rule])\n",
    "\n",
    "        if data_dict[\"enc_rules\"] != []:\n",
    "            data_for_df.append(data_dict)\n",
    "\n",
    "    return data_for_df\n",
    "\n",
    "\n",
    "def get_df(rule2rule_id: dict, data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    searches = convert_rules2regex(rule2rule_id)\n",
    "    data_for_df = get_data_for_df(data, searches)\n",
    "    df = pd.DataFrame.from_dict(data_for_df)\n",
    "    df = df.reset_index()\n",
    "       \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 132680/132680 [03:06<00:00, 710.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>samples</th>\n",
       "      <th>rules</th>\n",
       "      <th>enc_rules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Two years earlier , Officer TARGET was killed ...</td>\n",
       "      <td>[officer killed]</td>\n",
       "      <td>[24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Police Chief PERSON said Randolph was found sh...</td>\n",
       "      <td>[police shot]</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>In the latest incident , Chief Superintendent ...</td>\n",
       "      <td>[police shots]</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Chief TARGET of Penn Township police entered t...</td>\n",
       "      <td>[police shot]</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A man was was fatally shot by a police officer...</td>\n",
       "      <td>[police shot, officer shot]</td>\n",
       "      <td>[5, 25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            samples  \\\n",
       "0      0  Two years earlier , Officer TARGET was killed ...   \n",
       "1      1  Police Chief PERSON said Randolph was found sh...   \n",
       "2      2  In the latest incident , Chief Superintendent ...   \n",
       "3      3  Chief TARGET of Penn Township police entered t...   \n",
       "4      4  A man was was fatally shot by a police officer...   \n",
       "\n",
       "                         rules enc_rules  \n",
       "0             [officer killed]      [24]  \n",
       "1                [police shot]       [5]  \n",
       "2               [police shots]       [6]  \n",
       "3                [police shot]       [5]  \n",
       "4  [police shot, officer shot]   [5, 25]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = get_df(rule2rule_id, df_train)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Development and Test data\n",
    "\n",
    "Just as for the Train data, we need a dataframe with a sample, its corresponding rules and the rule IDs. Moreover, we need to add the labels and the label IDs that we obtained earlier when reading in the test data. We do this by merging the the new Dataframe with sample, rule and rule encoding only with the development and test dataframe that contain the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dev_test_df(rule2rule_id: dict, data: pd.DataFrame, label_id2label: dict) -> pd.DataFrame:\n",
    "\n",
    "    test_data_without_labels = get_df(rule2rule_id, data)\n",
    "    test_data = test_data_without_labels.merge(data, how='inner').rename(columns={\"label\": \"enc_labels\"})\n",
    "    test_data[\"labels\"] = test_data['enc_labels'].map(label_id2label)\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20673/20673 [00:27<00:00, 740.24it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_data = get_dev_test_df(rule2rule_id, df_dev, label_id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 48193/48193 [01:02<00:00, 765.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>samples</th>\n",
       "      <th>rules</th>\n",
       "      <th>enc_rules</th>\n",
       "      <th>enc_labels</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[ ] TARGET / Chicago Tribune Lake County Major...</td>\n",
       "      <td>[police shooting]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Round Lake police shooting Round Lake police s...</td>\n",
       "      <td>[police shooting]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PERSON shooting PERSON shooting TARGET / Chica...</td>\n",
       "      <td>[police shooting]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Scene of Round Lake police shooting Scene of R...</td>\n",
       "      <td>[police shooting]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>involved shooting TARGET / Chicago Tribune The...</td>\n",
       "      <td>[officer killed, officer shooting]</td>\n",
       "      <td>[24, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            samples  \\\n",
       "0      0  [ ] TARGET / Chicago Tribune Lake County Major...   \n",
       "1      1  Round Lake police shooting Round Lake police s...   \n",
       "2      2  PERSON shooting PERSON shooting TARGET / Chica...   \n",
       "3      3  Scene of Round Lake police shooting Scene of R...   \n",
       "4      4  involved shooting TARGET / Chicago Tribune The...   \n",
       "\n",
       "                                rules enc_rules  enc_labels    labels  \n",
       "0                   [police shooting]       [9]           0  negative  \n",
       "1                   [police shooting]       [9]           0  negative  \n",
       "2                   [police shooting]       [9]           0  negative  \n",
       "3                   [police shooting]       [9]           0  negative  \n",
       "4  [officer killed, officer shooting]  [24, 29]           0  negative  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = get_dev_test_df(rule2rule_id, df_test, label_id2label)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to sparse matrix\n",
    "\n",
    "The Train, Test and Development data that we just stored as Pandas Dataframes should now be converted into a Scipy sparse matrix. The rows of the sparse matrix are the samples and the columns the rules. It is also one-hot-encoded (a cell is 1 if a rule matches a sample.) We inizialize it as an array in the correct size (samples x rules) and set it to 1 if a rule matches the sample. In the end, the array is converted to a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rule_matches_z_matrix(df: pd.DataFrame) -> sp.csr_matrix:\n",
    "\n",
    "    z_array = np.zeros((len(df[\"index\"].values), len(rule2rule_id)))\n",
    "\n",
    "    for index in tqdm(df[\"index\"]):\n",
    "        enc_rules = df.iloc[index-1]['enc_rules']\n",
    "        for enc_rule in enc_rules:\n",
    "            z_array[index][enc_rule] = 1\n",
    "\n",
    "    rule_matches_z_matrix_sparse = sp.csr_matrix(z_array)\n",
    "\n",
    "    return rule_matches_z_matrix_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 132632/132632 [00:41<00:00, 3179.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train_rule_matches_z = get_rule_matches_z_matrix(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 20675/20675 [00:07<00:00, 2858.21it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_rule_matches_z = get_rule_matches_z_matrix(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 48238/48238 [00:18<00:00, 2637.03it/s]\n"
     ]
    }
   ],
   "source": [
    "test_rule_matches_z = get_rule_matches_z_matrix(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Emilie/Uni/2021WS/DS_project/data/police_killing\\\\processed\\\\test_rule_matches_z.lib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(os.path.join(data_path, \"processed\")).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dump(sp.csr_matrix(mapping_rules_labels_t), os.path.join(data_path, \"processed\", T_MATRIX_TRAIN))\n",
    "\n",
    "dump(train_data[\"samples\"], os.path.join(data_path, \"processed\", TRAIN_SAMPLES_OUTPUT))\n",
    "train_data[\"samples\"].to_csv(os.path.join(data_path, \"processed\", TRAIN_SAMPLES_CSV), header=True)\n",
    "dump(train_rule_matches_z, os.path.join(data_path, \"processed\", Z_MATRIX_TRAIN))\n",
    "\n",
    "dump(dev_data[[\"samples\", \"labels\", \"enc_labels\"]], os.path.join(data_path, \"processed\", DEV_SAMPLES_OUTPUT))\n",
    "dev_data[[\"samples\", \"labels\", \"enc_labels\"]].to_csv(os.path.join(data_path, \"processed\", DEV_SAMPLES_CSV), header=True)\n",
    "dump(dev_rule_matches_z, os.path.join(data_path, \"processed\", Z_MATRIX_DEV))\n",
    "\n",
    "dump(test_data[[\"samples\", \"labels\", \"enc_labels\"]], os.path.join(data_path, \"processed\", TEST_SAMPLES_OUTPUT))\n",
    "test_data[[\"samples\", \"labels\", \"enc_labels\"]].to_csv(os.path.join(data_path, \"processed\", TEST_SAMPLES_CSV), header=True)\n",
    "dump(test_rule_matches_z, os.path.join(data_path, \"processed\", Z_MATRIX_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
