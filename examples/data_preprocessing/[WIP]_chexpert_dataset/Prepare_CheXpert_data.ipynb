{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheXpert Dataset - Download and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to download and preprocess the CheXpert dataset for making weakly supervised experiments.\n",
    "\n",
    "The original CheXpert paper, \"CheXpert: A large chest radiograph dataset with uncertainty labels and expert comparison\" by Irvin et al. (2019), can be found here: https://arxiv.org/pdf/1901.07031.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CheXpert training set is composed of chest radiographs, which were annotated on the basis of reports using the rule-based CheXpert labeler. Each image is labeled with respect 12 pathologies as well as the observations \"No Finding\" and \"Support Devices\". For each of these categories, except \"No Finding\", the assigned weak label is either: (Irvin et al. (2019))\n",
    "\n",
    "- positive (1.0)\n",
    "- negative (0.0)\n",
    "- not mentioned (blank)\n",
    "- uncertain (-1.0) \n",
    "\n",
    "The development set was annotated by radiologists and therefore only contains the binary labels: (Irvin et al. (2019))\n",
    "\n",
    "- positive (1.0) \n",
    "- negative (0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting access to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can register for obtaining the data under the following link: https://stanfordmlgroup.github.io/competitions/chexpert/. Once the registration is finished, you should receive an email which contains links for two different versions of the dataset, the original CheXpert dataset (around 439 GB) and a version with downsampled resolution (around 11 GB). The code below uses the downsampled version. Please unzip the downloaded folder in a directory of your choice and don't change the filenames or the folder structure, otherwise you might need to change some of the paths used in the following code in order for it to run properly. The zip file you obtained should contain a training and a validation set. The CheXpert test set is not publicly available, as it is used for the CheXpert competition (see link above). The reports that were used to label the images are also unavailable.\n",
    "\n",
    "Please note that some output of the code below is not displayed due to the \"Stanford University School of Medicine CheXpert Dataset Research Use Agreement\" which can be found here: https://stanfordmlgroup.github.io/competitions/chexpert/.\n",
    "Please run the code yourself with the data you downloaded from the above link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define storing locations for the preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to save the preprocessed data on your computer, please specify a path to the location in which you want to store the data where \"storing_location_path\" is mentioned in the code underneath.\n",
    "\n",
    "At the end of the tutorial, you will be presented two options of storing the preprocessed data:\n",
    "\n",
    "- storing each preprocessed image tensor and its corresponding labels in a separate .npz file (~ 35 GB in total)\n",
    "- storing each preprocessed image as a .jpg file and saving all of the labels in a joblib file (~ 2 GB in total)\n",
    "\n",
    "Plese note that in both approaches, the training and validation set will be stored separately. \n",
    "If you wish to store the data, please create two folders, named \"train_images\" and \"valid_images\" respectively, in your specified location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storing_location = \"storing_location_path\"\n",
    "\n",
    "# joblib files in which labels are stored if second option is chosen\n",
    "joblib_labels_train = os.path.join(storing_location, 'chexpert_data_train_labels.joblib')\n",
    "joblib_labels_valid = os.path.join(storing_location, 'chexpert_data_valid_labels.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load the files train.csv and valid.csv, which accompany the images. First, please change the working directory to the appropriate location by inserting the path to the folder in which you stored train.csv and valid.csv where \"data_path\" is mentioned in the code. If you didn't change the folder structure, this path should end with \"\\CheXpert-v1.0-small\\CheXpert-v1.0-small\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data_path\"\n",
    "os.chdir(path) # change working directory to appropriate location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first five rows of the raw training data. \n",
    "\n",
    "Please note that the small dataframe displayed below is entirely made up of fake entries. If you want to see the true data, please run training_set.head(5) yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient99999/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient99999/study2/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path     Sex  Age  \\\n",
       "0  CheXpert-v1.0-small/train/patient99999/study1/...  Female   44   \n",
       "1  CheXpert-v1.0-small/train/patient99999/study2/...  Female   48   \n",
       "\n",
       "  Frontal/Lateral AP/PA No Finding Enlarged Cardiomediastinum Cardiomegaly  \\\n",
       "0         Frontal    AP        NaN                        NaN          NaN   \n",
       "1         Frontal    AP        1.0                        NaN          NaN   \n",
       "\n",
       "  Lung Opacity Lung Lesion Edema Consolidation Pneumonia Atelectasis  \\\n",
       "0          NaN         NaN  -1.0           NaN       NaN         NaN   \n",
       "1          NaN        -1.0   NaN           NaN       NaN         NaN   \n",
       "\n",
       "  Pneumothorax Pleural Effusion Pleural Other  Fracture Support Devices  \n",
       "0          NaN              NaN           NaN       1.0             NaN  \n",
       "1          NaN              NaN           NaN      -1.0             NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe with fake entries for demonstration purposes\n",
    "\n",
    "fake_entries = list(zip([\"CheXpert-v1.0-small/train/patient99999/study1/...\", \"CheXpert-v1.0-small/train/patient99999/study2/...\"],\n",
    "                        [\"Female\", \"Female\"], [44, 48], [\"Frontal\", \"Frontal\"], [\"AP\", \"AP\"], [\"NaN\", 1.0],\n",
    "                        [\"NaN\", \"NaN\"], [\"NaN\", \"NaN\"], [\"NaN\", \"NaN\"], [\"NaN\", -1.0], [-1.0, \"NaN\"], [\"NaN\", \"NaN\"],\n",
    "                        [\"NaN\", \"NaN\"], [\"NaN\", \"NaN\"], [\"NaN\", \"NaN\"], [\"NaN\", \"NaN\"], [\"NaN\", \"NaN\"], \n",
    "                        [1.0, -1.0], [\"NaN\", \"NaN\"]))\n",
    "\n",
    "fake_training_set = pd.DataFrame(data = fake_entries, index = None, columns = training_set.columns, dtype = None, copy = None)\n",
    "\n",
    "fake_training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in training set: 223414\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in training set:\", training_set.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each observation in the training set consists of a path to an image, some additional information about the patient and the nature of the image, as well as the weak labels for all 14 classes. 12 of the classes, \"Enlarged Cardiomediastinum\" to \"Fracture\", are considered pathologies. \"No Finding\" is assigned the label 1 (meaning \"positive\") if no pathology was marked as positive (1.0) or uncertain (-1.0) for this observation. Labels which were blank (meaning that the pathology was not mentioned in the report) turned into NaNs when loading the data.\n",
    "\n",
    "The training set has a total of 223414 observations. (Irvin et al. (2019))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_set = pd.read_csv(\"valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00000/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study2/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>82</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path     Sex  Age  \\\n",
       "0  CheXpert-v1.0-small/train/patient00000/study1/...    Male   65   \n",
       "1  CheXpert-v1.0-small/train/patient00001/study2/...  Female   82   \n",
       "\n",
       "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
       "0         Frontal    AP         0.0                         0.0           0.0   \n",
       "1         Lateral   NaN         0.0                         0.0           0.0   \n",
       "\n",
       "   Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
       "0           1.0          0.0    1.0            0.0        0.0          0.0   \n",
       "1           0.0          1.0    0.0            0.0        0.0          0.0   \n",
       "\n",
       "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \n",
       "0           0.0               0.0            0.0       0.0              0.0  \n",
       "1           0.0               0.0            0.0       0.0              1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe with fake entries for demonstration purposes\n",
    "\n",
    "fake_entries = list(zip([\"CheXpert-v1.0-small/train/patient00000/study1/...\", \"CheXpert-v1.0-small/train/patient00001/study2/...\"],\n",
    "                        [\"Male\", \"Female\"], [65, 82], [\"Frontal\", \"Lateral\"], [\"AP\", \"NaN\"], [0.0, 0.0],\n",
    "                        [0.0, 0.0], [0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 0.0], [0.0, 0.0],\n",
    "                        [0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 1.0]))\n",
    "\n",
    "fake_validation_set = pd.DataFrame(data = fake_entries, index = None, columns = training_set.columns, dtype = None, copy = None)\n",
    "\n",
    "fake_validation_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in validation set: 234\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in validation set:\", validation_set.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the validation set has the same structure as the training set. However, the validation set only uses positive (1.0) and negative (0.0) labels and no uncertainty (-1.0) or not-mentioned labels (blank).\n",
    "\n",
    "The validation set contains 234 observations. (Irvin et al. (2019))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, some statistics are computed in order to get an idea about the label distribution in the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Number of non-NaN labels    Number of datapoints\n",
      "--------------------------  ----------------------\n",
      "                         3                   64386\n",
      "                         4                   50893\n",
      "                         2                   50672\n",
      "                         5                   23828\n",
      "                         1                   23185\n",
      "                         6                    7922\n",
      "                         7                    1960\n",
      "                         8                     294\n",
      "                         0                     250\n",
      "                         9                      19\n",
      "                        10                       5\n"
     ]
    }
   ],
   "source": [
    "training_labels = training_set.iloc[:, -13:-1]\n",
    "labels_per_row = training_labels.count(axis = 1) # number of non-NaN labels per row in the training set\n",
    "\n",
    "vals = pd.DataFrame(labels_per_row.value_counts())\n",
    "\n",
    "# make a table\n",
    "val_list = [(i, vals[0][i]) for i in vals.index]\n",
    "    \n",
    "print(tabulate(val_list, headers = [\"Number of non-NaN labels\", \"Number of datapoints\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, most training samples have at least a few pathologies, for which they have a label which is not blank, meaning it is either positive (1.0), negative (0.0) or uncertain (-1.0). Nevertheless, there are 250 observations for which none of the 12 pathologies were mentioned in the corresponding report.\n",
    "\n",
    "The following two tables give an idea about the label distribution for the different pathologies in the training set and in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in the training set: \n",
      "\n",
      "Pathology                     -1.0    0.0     1.0\n",
      "--------------------------  ------  -----  ------\n",
      "Enlarged Cardiomediastinum   12403  21638   10798\n",
      "Cardiomegaly                  8087  11116   27000\n",
      "Lung Opacity                  5598   6599  105581\n",
      "Lung Lesion                   1488   1270    9186\n",
      "Edema                        12984  20726   52246\n",
      "Consolidation                27742  28097   14783\n",
      "Pneumonia                    18770   2799    6039\n",
      "Atelectasis                  33739   1328   33376\n",
      "Pneumothorax                  3145  56341   19448\n",
      "Pleural Effusion             11628  35396   86187\n",
      "Pleural Other                 2653    316    3523\n",
      "Fracture                       642   2512    9040\n"
     ]
    }
   ],
   "source": [
    "val_list = []\n",
    "for cond in training_labels.columns:\n",
    "    vals = np.array(pd.Categorical(training_labels[cond], categories = [-1.0, 0.0, 1.0]).value_counts().sort_index(ascending = True))\n",
    "    val_list.append([cond, vals[0], vals[1], vals[2]])\n",
    "\n",
    "print(\"Label distribution in the training set:\", \"\\n\")\n",
    "print(tabulate(val_list, headers = [\"Pathology\", \"-1.0\", \"0.0\", \"1.0\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in the validation set: \n",
      "\n",
      "Pathology                     0.0    1.0\n",
      "--------------------------  -----  -----\n",
      "Enlarged Cardiomediastinum    125    109\n",
      "Cardiomegaly                  166     68\n",
      "Lung Opacity                  108    126\n",
      "Lung Lesion                   233      1\n",
      "Edema                         189     45\n",
      "Consolidation                 201     33\n",
      "Pneumonia                     226      8\n",
      "Atelectasis                   154     80\n",
      "Pneumothorax                  226      8\n",
      "Pleural Effusion              167     67\n",
      "Pleural Other                 233      1\n",
      "Fracture                      234      0\n"
     ]
    }
   ],
   "source": [
    "validation_labels = validation_set.iloc[:, -13:-1]\n",
    "\n",
    "val_list = []\n",
    "for cond in validation_labels.columns:\n",
    "    vals = np.array(pd.Categorical(validation_labels[cond],categories = [0.0, 1.0]).value_counts().sort_index(ascending=True))\n",
    "    val_list.append([cond, vals[0], vals[1]])\n",
    "        \n",
    "print(\"Label distribution in the validation set:\", \"\\n\")\n",
    "print(tabulate(val_list, headers = [\"Pathology\", \"0.0\", \"1.0\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, some observations like \"Fracture\" or \"Lung Lesion\", which are positively mentioned (i.e. label 1.0) for numerous observations in the training set, barely appear or don't appear at all in the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have familiarized ourselves with the labels in the training and in the validation set, let's take a look at an example image from the training set. In order to do that, we first need to create paths that lead to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to training images\n",
    "image_paths_train = [os.path.join(path[: path.find(\"CheXpert-v1.0-small\")], \"CheXpert-v1.0-small\", p) for p in training_set[\"Path\"]]\n",
    "\n",
    "# paths to validation images\n",
    "image_paths_valid = [os.path.join(path[: path.find(\"CheXpert-v1.0-small\")], \"CheXpert-v1.0-small\", p) for p in validation_set[\"Path\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = Image.open(image_paths_train[0]).convert('RGB')\n",
    "plt.imshow(sample_image)\n",
    "plt.show()\n",
    "print(\"Dimensions of image:\", sample_image.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images in the (downsampled) dataset have a dimensionality of around 390 x 320 pixels, however, the individual image sizes vary. (Garbin et al. (2021))\n",
    "\n",
    "Now we can define a transform sequence which will be used to preprocess the images. The images are:\n",
    "\n",
    "- firstly, resized to 224 x 224 pixels, since this is a requirement for many pre-trained CNNs in PyTorch;\n",
    "- secondly, normalized with the mean and standard deviation from ImageNet.\n",
    "\n",
    "Such transformations have previously been applied by several other submissions regarding CheXpert on GitHub such as:\n",
    "[this](https://github.com/gaetandi/cheXpert/blob/master/cheXpert_final.ipynb) and [this](https://github.com/Stomper10/CheXpert/blob/master/CheXpert_DenseNet121_FL.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_list = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization from ImageNet\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is image transformation and preparation of the dataset for PyTorch's DataLoader, which is done with the `CheXpertDatasetProcessor` class.\n",
    "\n",
    "The structure of the class was inspired by the GitHub submissions credited above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from image preprocessing, an important feature of the `CheXpertDatasetProcessor` class is the handling of the uncertainty labels. The arguments `to_ones`, `to_zeros` and `to_ignore` each take a list consisting of pathologies as their input and transform the uncertainty labels for these pathologies accordingly. In particular:\n",
    "\n",
    "- `to_ones`: pathologies for which uncertainty labels (-1.0) should be turned to positive (1.0)\n",
    "- `to_zeros`: pathologies for which uncertainty labels (-1.0) should be turned to negative (0.0)\n",
    "- `to_ignore`: pathologies for which uncertainty labels (-1.0) should be turned to nan\n",
    "\n",
    "Not changing the uncertainty labels to either 1.0, 0.0 or nan results in training the model with 3 possible classes (positive, negative and uncertain). These 4 methods of handling the uncertainty labels were also described in the original CheXpert paper by Irvin et al. (2019).\n",
    "\n",
    "If you have already saved the transformed images but wish to experiment with different settings of `to_ones`, `to_zeros` or `to_ignore`, you can set the `return_image` parameter of the class to False, so that only the labels are returned.\n",
    "\n",
    "The \"Support Device\" label as well as the \"No Finding\" label is dropped for all instances, since support devices do not count as pathologies and the \"No Finding\" label only depends on the labels for the remaining 12 pathologies.\n",
    "\n",
    "The \"blank\" labels, indicating that an observation was not mentioned in the corresponding report, will be treated as \"uncertain\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXpertDatasetProcessor():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 path: str,\n",
    "                 subset: str, \n",
    "                 image_paths: List[str], \n",
    "                 number_of_images: int,  \n",
    "                 transform_sequence: List = None,\n",
    "                 to_ones: List[str] = None,\n",
    "                 to_zeros: List[str] = None, \n",
    "                 to_ignore: List[str] = None,\n",
    "                 return_image: bool = True):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path: path to the folder where train.csv and valid.csv are stored\n",
    "            subset: either \"train\" to load the train.csv or \"valid\" to load valid.csv\n",
    "            image_paths: paths to the images\n",
    "            number_of_images: number of images in the dataset\n",
    "            transform_sequence: sequence used to transform the images\n",
    "            to_ones: list of pathologies for which uncertainty labels should be replaced by 1\n",
    "            to_zeros: list of pathologies for which uncertainty labels should be replaced by 0\n",
    "            to_ignore: list of pathologies for which uncertainty labels should be ignored (label will be turned to nan)\n",
    "            return_image: True: image tensor and labels are returned, False: only labels are returned\n",
    "        Returns: \n",
    "            224 x 224 image tensor and a corresponding tensor containing 12 labels\n",
    "        \"\"\"\n",
    "        \n",
    "        self.path = path\n",
    "        self.subset = subset\n",
    "        self.image_paths = image_paths\n",
    "        self.number_of_images = number_of_images\n",
    "        self.transform_sequence = transform_sequence\n",
    "        self.to_ones = to_ones\n",
    "        self.to_zeros = to_zeros\n",
    "        self.to_ignore = to_ignore\n",
    "        self.return_image = return_image\n",
    "        \n",
    "    def process_chexpert_dataset(self):\n",
    "        \n",
    "        # read dataset\n",
    "        if self.subset == \"train\":\n",
    "            data = pd.read_csv(\"train.csv\")\n",
    "            \n",
    "        elif self.subset == \"valid\":\n",
    "            data = pd.read_csv(\"valid.csv\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid subset, please choose either 'train' or 'valid'\")\n",
    "            \n",
    "        pathologies = data.iloc[:, -13:-1].columns\n",
    "        \n",
    "        # prepare labels\n",
    "        data.iloc[:, -13:-1] = data.iloc[:, -13:-1].replace(float(\"nan\"), -1) # blank labels -> uncertain\n",
    "        \n",
    "        if self.to_ones is not None:\n",
    "            if all(p in pathologies for p in self.to_ones): # check whether arguments are valid pathologies\n",
    "                data[self.to_ones] = data[self.to_ones].replace(-1, 1) # replace uncertainty labels with ones\n",
    "            else:\n",
    "                raise ValueError(\"List supplied to to_ones contains invalid pathology, please choose from:\",\n",
    "                                 list(pathologies))\n",
    "            \n",
    "        if self.to_zeros is not None:\n",
    "            if all(p in pathologies for p in self.to_zeros):\n",
    "                    data[self.to_zeros] = data[self.to_zeros].replace(-1, 0) # replace uncertainty labels with zeros\n",
    "            else:\n",
    "                raise ValueError(\"List supplied to to_zeros contains invalid pathology, please choose from:\",\n",
    "                                 list(pathologies))\n",
    "            \n",
    "        if self.to_ignore is not None:\n",
    "            if all(p in pathologies for p in self.to_ignore):\n",
    "                    data[self.to_ignore] = data[self.to_ignore].replace(-1, float(\"nan\")) # replace uncertainty labels with nan\n",
    "            else:\n",
    "                raise ValueError(\"List supplied to to_ignore contains invalid pathology, please choose from:\",\n",
    "                                     list(pathologies))\n",
    "        \n",
    "        self.data = data\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        \"\"\"\n",
    "        index: index of example that should be retrieved\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.return_image not in [True, False]:\n",
    "            raise ValueError(\"Please set return_image argument either to True or False\")\n",
    "        \n",
    "        image_labels = self.data.iloc[index, -13:-1]\n",
    "        \n",
    "        if self.return_image is False: # only labels are returned, not the images\n",
    "            return torch.tensor(image_labels)\n",
    "        \n",
    "        else:\n",
    "            image_name = self.image_paths[index]\n",
    "        \n",
    "            patient_image = Image.open(image_name).convert('RGB')\n",
    "        \n",
    "            if self.transform_sequence is not None:\n",
    "                patient_image = self.transform_sequence(patient_image) # apply the transform_sequence if one is specified\n",
    "        \n",
    "            else:\n",
    "                # even if no other transformation is applied, the image should be turned into a tensor\n",
    "                to_tensor = transforms.ToTensor()\n",
    "                patient_image = to_tensor(patient_image)\n",
    "            \n",
    "            return patient_image, torch.tensor(image_labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.number_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "chexpert_train = CheXpertDatasetProcessor(path = path, subset = \"train\", image_paths = image_paths_train,\n",
    "                                          number_of_images = training_set.shape[0], transform_sequence = transform_list)\n",
    "chexpert_train.process_chexpert_dataset()\n",
    "\n",
    "# prepare validation data\n",
    "chexpert_valid = CheXpertDatasetProcessor(path = path, subset = \"valid\", image_paths = image_paths_valid,\n",
    "                                          number_of_images = validation_set.shape[0], transform_sequence = transform_list)\n",
    "chexpert_valid.process_chexpert_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given index, the `__getitem__` function returns the tensor representing the preprocessed image as well as a tensor containing all of the labels for this observation.\n",
    "\n",
    "Let's take a look at what `__getitem__` returns for the training example with index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_train.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image tensor: torch.Size([3, 224, 224])\n",
      "Shape of label tensor: torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "shape_of_image_tensor = chexpert_train.__getitem__(0)[0].shape\n",
    "shape_of_label_tensor = chexpert_train.__getitem__(0)[1].shape\n",
    "\n",
    "print(\"Shape of image tensor:\", shape_of_image_tensor)\n",
    "print(\"Shape of label tensor:\", shape_of_label_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the same example, this time using the `to_ones`, `to_zeros` and `to_ignore` arguments to see exactly what they do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example using to_ones, to_zeros and to_ignore\n",
    "all_pathologies = training_set.iloc[:, -13:-1].columns\n",
    "chexpert_train_alt = CheXpertDatasetProcessor(path = path, subset = \"train\", image_paths = image_paths_train,\n",
    "                                          number_of_images = training_set.shape[0], transform_sequence = transform_list,\n",
    "                                          to_ones = all_pathologies[0:2],\n",
    "                                          to_zeros = all_pathologies[2:4],\n",
    "                                          to_ignore = all_pathologies[4:6],\n",
    "                                          return_image = False)\n",
    "chexpert_train_alt.process_chexpert_dataset()\n",
    "chexpert_train_alt.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the uncertainty labels for the first 6 pathologies changed depending on whether the name of the pathology was supplied to `to_ones`, `to_zeros` or `to_ignore`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to apply the preprocessing to our entire training and validation set and save the results for further use.\n",
    "\n",
    "Remember, the two different options of storing the data provided in this tutorial are:\n",
    "\n",
    "- storing each preprocessed image tensor and its corresponding labels separate .npz file (~ 35 GB in total)\n",
    "- storing each resized image as a .jpg file and saving all of the labels in a joblib file (~ 2 GB in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data as .npz files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer storing the images and labels in .npz files, please run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the training set\n",
    "for i in tqdm(range(0, training_set.shape[0])):\n",
    "    x = chexpert_train.__getitem__(i)\n",
    "    np.savez_compressed(os.path.join(storing_location, \"train_images\", \"image_\" + str(i) + \".npz\"), \n",
    "                        image = x[0], label = x[1])\n",
    "    \n",
    "# store the validation set\n",
    "for i in tqdm(range(0, validation_set.shape[0])):\n",
    "    x = chexpert_valid.__getitem__(i)\n",
    "    np.savez_compressed(os.path.join(storing_location, \"valid_images\", \"image_\" + str(i) + \".npz\"), \n",
    "                        image = x[0], label = x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the `np.load` function returns an array and not a tensor, so the \"image\" result has to be transposed and turned into a tensor again. The labels also need to be converted to a tensor again. Here is a quick example how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "example = np.load(os.path.join(storing_location, \"train_images\", \"image_\" + str(0) + \".npz\"))\n",
    "print(to_tensor(example[\"image\"].transpose(1,2,0)))\n",
    "print(torch.tensor(example[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with original output from __getitem__()\n",
    "chexpert_train.__getitem__(0) # same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store images as .jpg files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to store the resized images as .jpg files and the labels in joblib files, you can run the code below.\n",
    "Please note that due to the negative values that result from the normalization, the images are saved without the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transformations (without normalization)\n",
    "\n",
    "transform_list_resize = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# store the training images\n",
    "chexpert_train_resize = CheXpertDatasetProcessor(path = path, subset = \"train\", image_paths = image_paths_train, number_of_images = training_set.shape[0], transform_sequence = transform_list_resize)\n",
    "chexpert_train_resize.process_chexpert_dataset()\n",
    "\n",
    "for i in tqdm(range(0, training_set.shape[0])):\n",
    "    ex = chexpert_train_resize.__getitem__(i)[0]\n",
    "    save_image(ex, os.path.join(storing_location, \"train_images\", \"image_\" + str(i) + \".jpg\"))\n",
    "    \n",
    "# store the training labels\n",
    "joblib_file = open(joblib_labels_train, 'wb')\n",
    "\n",
    "chexpert_train_labels = CheXpertDatasetProcessor(path = path, subset = \"train\", image_paths = image_paths_train, number_of_images = training_set.shape[0], return_image = False)\n",
    "chexpert_train_labels.process_chexpert_dataset()\n",
    "train_label_loader = DataLoader(chexpert_train_labels, batch_size = training_set.shape[0])\n",
    "dataiter = iter(train_label_loader)\n",
    "train_labels = dataiter.next()\n",
    "joblib.dump(train_labels, joblib_file, compress = 2)\n",
    "\n",
    "# store the validation images\n",
    "chexpert_valid_resize = CheXpertDatasetProcessor(path = path, subset = \"valid\", image_paths = image_paths_valid, number_of_images = validation_set.shape[0], transform_sequence = transform_list_resize)\n",
    "chexpert_valid_resize.process_chexpert_dataset()\n",
    "\n",
    "for i in tqdm(range(0, validation_set.shape[0])):\n",
    "    ex = chexpert_valid_resize.__getitem__(i)[0]\n",
    "    save_image(ex, os.path.join(storing_location, \"valid_images\", \"image_\" + str(i) + \".jpg\"))\n",
    "    \n",
    "# store the validation labels\n",
    "joblib_file = open(joblib_labels_valid, 'wb')\n",
    "\n",
    "chexpert_valid_labels = CheXpertDatasetProcessor(path = path, subset = \"valid\", image_paths = image_paths_valid, number_of_images = validation_set.shape[0], return_image = False)\n",
    "chexpert_valid_labels.process_chexpert_dataset()\n",
    "valid_label_loader = DataLoader(chexpert_valid_labels, batch_size = validation_set.shape[0])\n",
    "dataiter = iter(valid_label_loader)\n",
    "valid_labels = dataiter.next()\n",
    "joblib.dump(valid_labels, joblib_file, compress = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the preprocessing of the CheXpert data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CheXpert: A large chest radiograph dataset with uncertainty labels and expert comparison by Irvin et al. (2019):\n",
    "https://arxiv.org/pdf/1901.07031.pdf\n",
    "\n",
    "Structured dataset documentation: a datasheet for CheXpert by Garbin et al. (2021):\n",
    "https://arxiv.org/pdf/2105.03020.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
