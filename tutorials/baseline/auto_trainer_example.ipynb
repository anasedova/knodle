{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "obvious-chicago",
   "metadata": {},
   "source": [
    "# Auto Trainer Tutorial\n",
    "\n",
    "Here we want to show you an maximally easy example how to use Knodle out-of-the box. Therefor this tutorial contains\n",
    "the following steps:\n",
    "1. Download from Knodle Server and load into memory\n",
    "2. Initialize model and data for a TF_IDF and Logistic Regression example\n",
    "3. Use AutoTrainer to use 2 weak training strategies\n",
    "\n",
    "All the steps are discussed in more detail below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-gossip",
   "metadata": {},
   "source": [
    "### Data \n",
    " \n",
    "We will use a preprocessed version of the IMDb dataset, see \n",
    "for further creation of the dataset. Instead of a download, you can also use this tutorial to create the data yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frank-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "imdb_data_dir = os.path.join(os.getcwd(), \"data\", \"imdb\")\n",
    "processed_data_dir = os.path.join(imdb_data_dir, \"processed\")\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "silver-venice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972b019d0d9d45229c95e59a677d14c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from minio import Minio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "client = Minio(\"knodle.dm.univie.ac.at\", secure=False)\n",
    "files = [\n",
    "    \"df_train.csv\", \"df_dev.csv\", \"df_test.csv\",\n",
    "    \"train_rule_matches_z.lib\", \"dev_rule_matches_z.lib\", \"test_rule_matches_z.lib\",\n",
    "    \"mapping_rules_labels_t.lib\"\n",
    "]\n",
    "\n",
    "for file in tqdm(files):\n",
    "    client.fget_object(\n",
    "        bucket_name=\"knodle\",\n",
    "        object_name=os.path.join(\"datasets/imdb/processed\", file),\n",
    "        file_path=os.path.join(processed_data_dir, file),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "declared-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "natural-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(processed_data_dir, \"df_train.csv\"))\n",
    "df_dev = pd.read_csv(os.path.join(processed_data_dir, \"df_dev.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(processed_data_dir, \"df_test.csv\"))\n",
    "\n",
    "mapping_rules_labels_t = joblib.load(os.path.join(processed_data_dir, \"mapping_rules_labels_t.lib\"))\n",
    "\n",
    "train_rule_matches_z = joblib.load(os.path.join(processed_data_dir, \"train_rule_matches_z.lib\"))\n",
    "dev_rule_matches_z = joblib.load(os.path.join(processed_data_dir, \"dev_rule_matches_z.lib\"))\n",
    "test_rule_matches_z = joblib.load(os.path.join(processed_data_dir, \"test_rule_matches_z.lib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unknown-roots",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>This film mildly entertaining neglects acknowl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25454</td>\n",
       "      <td>I originally saw premiere UK. I mesmerised it,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436</td>\n",
       "      <td>This excellent film characters adult swimming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3313</td>\n",
       "      <td>I really like Traci Lords. She greatest actres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6626</td>\n",
       "      <td>I picked DVD 1 discount, having idea it's (bu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             sample\n",
       "0        1979  This film mildly entertaining neglects acknowl...\n",
       "1       25454  I originally saw premiere UK. I mesmerised it,...\n",
       "2         436  This excellent film characters adult swimming ...\n",
       "3        3313  I really like Traci Lords. She greatest actres...\n",
       "4        6626  I picked DVD 1 discount, having idea it's (bu..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unusual-medicine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Z dimension: (40000, 6786)\n",
      "Train avg. matches per sample: 33.965325\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Z dimension: {train_rule_matches_z.shape}\")\n",
    "print(f\"Train avg. matches per sample: {train_rule_matches_z.sum() / train_rule_matches_z.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-reservation",
   "metadata": {},
   "source": [
    "### Preprocess data to TF_IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "after-thousand",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andst/.cache/virtual-envs/knodle/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def remove_stop_words(text: str) -> str:\n",
    "    text = ' '.join([word for word in text.split() if word not in (ENGLISH_STOP_WORDS)])\n",
    "    return text\n",
    "\n",
    "\n",
    "def np_to_tensor_dataset(x: np.ndarray):\n",
    "    if isinstance(x, sp.csr_matrix):\n",
    "        x = x.toarray()\n",
    "    x = torch.from_numpy(x)\n",
    "    x = TensorDataset(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_tfidf_dataset(\n",
    "        text_data: [str], force_create_new: bool = False, max_features: int = None\n",
    "):\n",
    "    \"\"\"Takes a list of strings, e.g. sentences, and transforms these in a simple TF-IDF representation\"\"\"\n",
    "    text_data = [remove_stop_words(t) for t in text_data]\n",
    "    vectorizer = TfidfVectorizer(min_df=2, max_features=max_features)\n",
    "    transformed_data = vectorizer.fit_transform(text_data)\n",
    "    dataset = np_to_tensor_dataset(transformed_data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "broke-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = create_tfidf_dataset(df_train[\"sample\"].tolist(), max_features=5000)\n",
    "X_dev = create_tfidf_dataset(df_dev[\"sample\"].tolist(), max_features=5000)\n",
    "X_test = create_tfidf_dataset(df_test[\"sample\"].tolist(), max_features=5000)\n",
    "\n",
    "y_dev = np_to_tensor_dataset(df_dev['label'].values)\n",
    "y_test = np_to_tensor_dataset(df_test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-renewal",
   "metadata": {},
   "source": [
    "## Training and evaluation\n",
    "\n",
    "The following code shows the usage of the majority trainer. It is a simple baseline, using the following steps:\n",
    "1. Restrict data to samples where at least one rule matches\n",
    "2. Use majority vote for cases where multiple rules match. If there's no clear winner, randomly choose between labels.\n",
    "3. Train on majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "interracial-extent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 11:49:31,924 knodle.trainer.trainer INFO     ======================================\n",
      "2021-04-01 11:49:31,925 knodle.trainer.trainer INFO     Training starts\n",
      "2021-04-01 11:49:31,926 knodle.trainer.trainer INFO     ======================================\n",
      "2021-04-01 11:49:31,927 knodle.trainer.trainer INFO     Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63793df7cc3b4b1eaf14a6b55c510c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 11:49:32,075 knodle.trainer.trainer INFO     Train loss: 0.691, Train accuracy: 0.763\n",
      "2021-04-01 11:49:32,205 knodle.trainer.trainer INFO     Train loss: 0.690, Train accuracy: 0.762\n",
      "2021-04-01 11:49:32,333 knodle.trainer.trainer INFO     Train loss: 0.689, Train accuracy: 0.761\n",
      "2021-04-01 11:49:32,461 knodle.trainer.trainer INFO     Train loss: 0.689, Train accuracy: 0.763\n",
      "2021-04-01 11:49:32,588 knodle.trainer.trainer INFO     Train loss: 0.688, Train accuracy: 0.763\n",
      "2021-04-01 11:49:32,712 knodle.trainer.trainer INFO     Train loss: 0.687, Train accuracy: 0.762\n",
      "2021-04-01 11:49:32,836 knodle.trainer.trainer INFO     Train loss: 0.687, Train accuracy: 0.762\n",
      "2021-04-01 11:49:32,956 knodle.trainer.trainer INFO     Train loss: 0.686, Train accuracy: 0.761\n",
      "2021-04-01 11:49:33,082 knodle.trainer.trainer INFO     Train loss: 0.686, Train accuracy: 0.761\n",
      "2021-04-01 11:49:33,184 knodle.trainer.trainer INFO     Epoch train loss: 0.6853720800132509\n",
      "2021-04-01 11:49:33,185 knodle.trainer.trainer INFO     Epoch train accuracy: 0.7613414624694047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebfdb13859144bfa6f9667eca9f3bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 11:49:33,339 knodle.trainer.trainer INFO     Epoch development accuracy: 0.4962\n",
      "2021-04-01 11:49:33,339 knodle.trainer.trainer INFO     Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f7d2718f8b4582b86abcdab4870a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 11:49:33,480 knodle.trainer.trainer INFO     Train loss: 0.680, Train accuracy: 0.755\n",
      "2021-04-01 11:49:33,598 knodle.trainer.trainer INFO     Train loss: 0.680, Train accuracy: 0.760\n",
      "2021-04-01 11:49:33,718 knodle.trainer.trainer INFO     Train loss: 0.680, Train accuracy: 0.759\n",
      "2021-04-01 11:49:33,835 knodle.trainer.trainer INFO     Train loss: 0.679, Train accuracy: 0.761\n",
      "2021-04-01 11:49:33,950 knodle.trainer.trainer INFO     Train loss: 0.679, Train accuracy: 0.761\n",
      "2021-04-01 11:49:34,068 knodle.trainer.trainer INFO     Train loss: 0.679, Train accuracy: 0.760\n",
      "2021-04-01 11:49:34,183 knodle.trainer.trainer INFO     Train loss: 0.679, Train accuracy: 0.760\n",
      "2021-04-01 11:49:34,303 knodle.trainer.trainer INFO     Train loss: 0.678, Train accuracy: 0.762\n",
      "2021-04-01 11:49:34,420 knodle.trainer.trainer INFO     Train loss: 0.678, Train accuracy: 0.762\n",
      "2021-04-01 11:49:34,512 knodle.trainer.trainer INFO     Epoch train loss: 0.6780885476974925\n",
      "2021-04-01 11:49:34,513 knodle.trainer.trainer INFO     Epoch train accuracy: 0.7623069104115674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4813d465c344bac85f09dc7af5a8a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 11:49:34,661 knodle.trainer.trainer INFO     Epoch development accuracy: 0.4962\n",
      "2021-04-01 11:49:34,661 knodle.trainer.trainer INFO     Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2a83b2b63e4758a224e8e03cc6a6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 11:49:34,797 knodle.trainer.trainer INFO     Train loss: 0.677, Train accuracy: 0.757\n",
      "2021-04-01 11:49:34,916 knodle.trainer.trainer INFO     Train loss: 0.676, Train accuracy: 0.761\n",
      "2021-04-01 11:49:35,035 knodle.trainer.trainer INFO     Train loss: 0.676, Train accuracy: 0.758\n",
      "2021-04-01 11:49:35,149 knodle.trainer.trainer INFO     Train loss: 0.676, Train accuracy: 0.760\n",
      "2021-04-01 11:49:35,266 knodle.trainer.trainer INFO     Train loss: 0.676, Train accuracy: 0.761\n",
      "2021-04-01 11:49:35,379 knodle.trainer.trainer INFO     Train loss: 0.675, Train accuracy: 0.761\n",
      "2021-04-01 11:49:35,498 knodle.trainer.trainer INFO     Train loss: 0.675, Train accuracy: 0.762\n",
      "2021-04-01 11:49:35,614 knodle.trainer.trainer INFO     Train loss: 0.675, Train accuracy: 0.762\n",
      "2021-04-01 11:49:35,732 knodle.trainer.trainer INFO     Train loss: 0.675, Train accuracy: 0.762\n",
      "2021-04-01 11:49:35,826 knodle.trainer.trainer INFO     Epoch train loss: 0.6750082468530935\n",
      "2021-04-01 11:49:35,827 knodle.trainer.trainer INFO     Epoch train accuracy: 0.7616706201984624\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c138e055fc7f4a339c1a5c49c9f12db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 11:49:35,973 knodle.trainer.trainer INFO     Epoch development accuracy: 0.4962\n",
      "2021-04-01 11:49:35,974 knodle.trainer.trainer INFO     ======================================\n",
      "2021-04-01 11:49:35,974 knodle.trainer.trainer INFO     Training done\n",
      "2021-04-01 11:49:35,974 knodle.trainer.trainer INFO     ======================================\n"
     ]
    }
   ],
   "source": [
    "from knodle.model.logistic_regression_model import LogisticRegressionModel\n",
    "from knodle.trainer.auto_trainer import AutoTrainer\n",
    "\n",
    "\n",
    "model = LogisticRegressionModel(X_train.tensors[0].shape[1], 2)\n",
    "\n",
    "maj_trainer = AutoTrainer(\n",
    "    name=\"majority\",\n",
    "    model=model,\n",
    "    mapping_rules_labels_t=mapping_rules_labels_t,\n",
    "    model_input_x=X_train,\n",
    "    rule_matches_z=train_rule_matches_z,\n",
    "    dev_model_input_x=X_dev,\n",
    "    dev_gold_labels_y=y_dev\n",
    ")\n",
    "\n",
    "maj_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "solid-church",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c957f41f6c6047b0869b0cad89e19266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5024\n"
     ]
    }
   ],
   "source": [
    "eval_dict, _ = maj_trainer.test(X_test, y_test)\n",
    "print(f\"Accuracy: {eval_dict.get('accuracy')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-mining",
   "metadata": {},
   "source": [
    "## Further readings\n",
    "\n",
    "1. The next tutorial would be %TODO\n",
    "2. Finally, we want to encourage you to head over to our repository \n",
    "[knodle-experiments](https://github.com/knodle/knodle-experiments)\n",
    "which adds a new layer of abstraction on top of Knodle, allowing you to easily create full benchmarking setups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
